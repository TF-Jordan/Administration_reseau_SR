# Monitoring Stack - ELK + APM + Metricbeat

Complete monitoring solution using ELK Stack (Elasticsearch, Logstash, Kibana) + Elastic APM + Metricbeat.

## ðŸ“Š Architecture

```
Application Logs (JSON) â†’ Filebeat â†’ Logstash â†’ Elasticsearch â†’ Kibana
Infrastructure Metrics  â†’ Metricbeat â†’ Elasticsearch â†’ Kibana
APM Traces             â†’ APM Server â†’ Elasticsearch â†’ Kibana
```

## ðŸŽ¯ What's Monitored

### Application Metrics (via Structured Logging)
- âœ… **HTTP Requests**: Method, path, status, duration_ms, correlation_id
- âœ… **Cache Operations**: hit/miss rate, latency, data size
- âœ… **Vector Search**: query latency, results count, similarity scores
- âœ… **ML Inference**: sentiment analysis timing, embedding generation
- âœ… **Database Queries**: query type, duration, slow query detection (>100ms)
- âœ… **Celery Tasks**: success/failure rate, retry count, duration

### Infrastructure Metrics (via Metricbeat)
- âœ… **Redis**: memory usage, commands/sec, keyspace stats
- âœ… **PostgreSQL**: connections, transactions/sec, cache hit ratio
- âœ… **Docker**: CPU/memory per container, network I/O
- âœ… **System**: CPU, memory, disk, network

### Distributed Tracing (via Elastic APM)
- âœ… **HTTP Transactions**: Complete request timeline
- âœ… **Exception Tracking**: Automatic error capture
- âœ… **Correlation ID**: End-to-end request tracing

## ðŸš€ Quick Start

### 1. Start Monitoring Stack

```bash
# Start all services (app + monitoring)
docker-compose up -d

# Check services health
docker-compose ps

# View logs
docker-compose logs -f
```

### 2. Access Dashboards

- **Kibana**: http://localhost:5601
- **Elasticsearch**: http://localhost:9200
- **APM**: http://localhost:5601/app/apm

### 3. Import Kibana Assets

```bash
# Import dashboards and visualizations
docker-compose exec kibana curl -X POST \
  http://localhost:5601/api/saved_objects/_import \
  -H "kbn-xsrf: true" \
  --form file=@/usr/share/kibana/dashboards/recommendation-dashboards.ndjson
```

## ðŸ“ˆ Key Metrics to Monitor

### Cache Performance
```
metric_type: cache_operation
Fields: cache_hit, cache_hit_type, duration_ms
```

**Kibana Query:**
```
event: cache_get AND metric_type: cache_operation
```

**Key Metrics:**
- Cache Hit Rate: `cache_hit:true / total cache operations`
- Average Latency: `avg(duration_ms)`

### API Performance
```
event: request_completed
Fields: method, path, status_code, duration_ms
```

**Kibana Query:**
```
event: request_completed AND path: "/api/v1/recommendations"
```

**Key Metrics:**
- P95 Response Time: `percentile(duration_ms, 95)`
- Error Rate: `status_code >= 400`

### Database Performance
```
metric_type: database_query
Fields: query_type, duration_ms, is_slow_query
```

**Kibana Query:**
```
metric_type: database_query AND is_slow_query: true
```

**Key Metrics:**
- Slow Queries: `is_slow_query:true`
- Queries by Type: `query_type: SELECT|INSERT|UPDATE|DELETE`

### ML Inference Performance
```
metric_type: ml_inference
Fields: model, operation, duration_ms, confidence
```

**Kibana Query:**
```
metric_type: ml_inference AND operation: sentiment_analysis
```

**Key Metrics:**
- Inference Time: `avg(duration_ms) by model`
- Confidence Distribution: `avg(confidence)`

## ðŸ” Correlation ID Tracing

Every request gets a `correlation_id` that propagates through:
1. HTTP Request â†’ API logs
2. Celery Task â†’ Background job logs
3. Database Query â†’ SQL logs
4. Cache Operation â†’ Redis logs
5. Vector Search â†’ Qdrant logs

**Search by Correlation ID:**
```
correlation_id: "550e8400-e29b-41d4-a716-446655440000"
```

This shows the complete execution chain!

## ðŸš¨ Configured Alerts

### 1. High Error Rate
- **Trigger**: >10 errors in 5 minutes
- **File**: `monitoring/kibana/rules/high-error-rate.json`
- **Action**: Log alert message

### 2. Slow API Response
- **Trigger**: >5 requests with duration >2s in 5 minutes
- **File**: `monitoring/kibana/rules/slow-api-response.json`
- **Action**: Log warning

### 3. Cache Low Hit Rate
- **Trigger**: >100 cache misses in 10 minutes
- **File**: `monitoring/kibana/rules/cache-low-hit-rate.json`
- **Action**: Log warning

## ðŸ“Š Available Dashboards

### 1. Recommendation System - Overview
- Logs by service
- Errors over time
- Response time distribution
- Top 10 endpoints

### 2. Application Metrics
- Cache hit/miss rate
- ML inference time
- Database query performance
- Vector search latency

### 3. Infrastructure Health
- Redis metrics (from Metricbeat)
- PostgreSQL metrics (from Metricbeat)
- Docker container metrics (from Metricbeat)

## ðŸ”§ Configuration Files

```
monitoring/
â”œâ”€â”€ filebeat/
â”‚   â””â”€â”€ filebeat.yml          # Log collection config
â”œâ”€â”€ logstash/
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â””â”€â”€ logstash.conf     # Log processing pipeline
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ logstash.yml      # Logstash settings
â”œâ”€â”€ metricbeat/
â”‚   â””â”€â”€ metricbeat.yml        # Infrastructure metrics config
â””â”€â”€ kibana/
    â”œâ”€â”€ dashboards/
    â”‚   â””â”€â”€ recommendation-dashboards.ndjson
    â””â”€â”€ rules/
        â”œâ”€â”€ high-error-rate.json
        â”œâ”€â”€ slow-api-response.json
        â””â”€â”€ cache-low-hit-rate.json
```

## ðŸ› Troubleshooting

### Check Elasticsearch Health
```bash
curl http://localhost:9200/_cluster/health?pretty
```

### View Metricbeat Logs
```bash
docker-compose logs metricbeat
```

### Test Logstash Pipeline
```bash
docker-compose exec logstash logstash -f /usr/share/logstash/pipeline/logstash.conf --config.test_and_exit
```

### Check Index Patterns
```bash
curl http://localhost:9200/_cat/indices?v
```

## ðŸ“– Useful Kibana Queries

### Find All Slow Requests
```
is_slow_request: true
```

### Cache Performance by Type
```
metric_type: cache_operation
Group by: cache_hit_type.keyword
```

### Database Queries by Type
```
metric_type: database_query
Visualize: query_type.keyword
```

### ML Inference Time Trend
```
metric_type: ml_inference
Y-axis: avg(duration_ms)
X-axis: @timestamp
Split by: model.keyword
```

## ðŸŽ“ Best Practices

1. **Always use correlation_id** when debugging issues
2. **Set up alerting** for critical metrics (error rate, latency)
3. **Monitor cache hit rate** - should be >70%
4. **Watch for slow queries** - optimize queries >100ms
5. **Track ML inference time** - ensure consistent performance
6. **Monitor Celery queue depth** - detect bottlenecks early

## ðŸ“š Documentation

- [Elastic Stack Guide](https://www.elastic.co/guide/index.html)
- [Filebeat Reference](https://www.elastic.co/guide/en/beats/filebeat/current/index.html)
- [Metricbeat Reference](https://www.elastic.co/guide/en/beats/metricbeat/current/index.html)
- [Elastic APM](https://www.elastic.co/guide/en/apm/guide/current/index.html)
- [Kibana Query Language](https://www.elastic.co/guide/en/kibana/current/kuery-query.html)
