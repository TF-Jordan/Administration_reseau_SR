# Logstash Pipeline Configuration for Recommendation System

input {
  # Receive logs from Filebeat
  beats {
    port => 5044
  }

  # Direct TCP input for application logs
  tcp {
    port => 5000
    codec => json_lines
    tags => ["direct_app_log"]
  }
}

filter {
  # Parse JSON logs from the application
  if [message] =~ /^\{/ {
    json {
      source => "message"
      target => "parsed"
    }

    # Move parsed fields to root
    if [parsed] {
      mutate {
        rename => {
          "[parsed][level]" => "level"
          "[parsed][logger]" => "logger"
          "[parsed][message]" => "log_message"
          "[parsed][timestamp]" => "app_timestamp"
          "[parsed][service]" => "service"
          "[parsed][request_id]" => "request_id"
          "[parsed][user_id]" => "user_id"
          "[parsed][product_id]" => "product_id"
          "[parsed][duration_ms]" => "duration_ms"
        }
      }
    }
  }

  # Parse container logs
  if [container][name] {
    mutate {
      add_field => {
        "container_name" => "%{[container][name]}"
      }
    }
  }

  # Add service identification based on container name
  if [container_name] =~ /recommendation-api/ {
    mutate {
      add_field => { "service_type" => "api" }
    }
  } else if [container_name] =~ /recommendation-worker/ {
    mutate {
      add_field => { "service_type" => "celery_worker" }
    }
  } else if [container_name] =~ /recommendation-beat/ {
    mutate {
      add_field => { "service_type" => "celery_beat" }
    }
  } else if [container_name] =~ /recommendation-flower/ {
    mutate {
      add_field => { "service_type" => "flower" }
    }
  }

  # Parse log levels and standardize
  if [level] {
    mutate {
      uppercase => ["level"]
    }
  }

  # Extract HTTP request info if present
  if [log_message] =~ /HTTP/ {
    grok {
      match => {
        "log_message" => "%{IP:client_ip}.*\"%{WORD:http_method} %{URIPATHPARAM:request_path} HTTP/%{NUMBER:http_version}\" %{NUMBER:http_status:int}"
      }
      tag_on_failure => []
    }
  }

  # Add geo-ip for client IPs (if available)
  if [client_ip] and [client_ip] != "-" and [client_ip] !~ /^(127\.|10\.|172\.(1[6-9]|2[0-9]|3[01])\.|192\.168\.)/ {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }

  # Calculate metrics for API requests
  if [duration_ms] {
    mutate {
      convert => { "duration_ms" => "float" }
    }
    
    # Categorize response time
    if [duration_ms] < 100 {
      mutate { add_field => { "response_category" => "fast" } }
    } else if [duration_ms] < 500 {
      mutate { add_field => { "response_category" => "normal" } }
    } else if [duration_ms] < 1000 {
      mutate { add_field => { "response_category" => "slow" } }
    } else {
      mutate { add_field => { "response_category" => "very_slow" } }
    }
  }

  # Tag error logs
  if [level] == "ERROR" or [level] == "CRITICAL" {
    mutate {
      add_tag => ["error"]
    }
  }

  # Add processing timestamp
  mutate {
    add_field => { "processed_at" => "%{@timestamp}" }
  }
}

output {
  # Output to Elasticsearch with dynamic index
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "recommendation-%{[service_type]:logs}-%{+YYYY.MM.dd}"
  }

  # Separate index for errors
  if "error" in [tags] {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "recommendation-errors-%{+YYYY.MM.dd}"
    }
  }
}
